#!/usr/bin/env python3
"""
Signal Generation Module for Quantitative Trading

This module provides comprehensive signal generation capabilities with:
- Multiple signal types (trend, mean reversion, momentum, volatility)
- Ensemble methods for combining signals
- Multi-core parallel processing
- Signal validation and filtering
- Performance tracking

Author: Manus AI
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from concurrent.futures import ProcessPoolExecutor
from joblib import Parallel, delayed
import warnings
warnings.filterwarnings('ignore')

class SignalGenerator:
    """
    Comprehensive signal generation for quantitative trading
    """
    
    def __init__(self, n_jobs=-1):
        self.n_jobs = n_jobs
        self.signal_cache = {}
        self.signal_performance = {}
        
    def generate_trend_signals(self, features, price_data):
        """
        Generate trend-following signals
        
        Args:
            features: DataFrame with technical features
            price_data: DataFrame with OHLCV data
            
        Returns:
            DataFrame with trend signals
        """
        signals = pd.DataFrame(index=features.index)
        
        # Moving Average Crossover Signals
        for short_period in [5, 10, 20]:
            for long_period in [20, 50, 100, 200]:
                if long_period > short_period:
                    short_ma_col = f'sma_{short_period}'
                    long_ma_col = f'sma_{long_period}'
                    
                    if short_ma_col in features.columns and long_ma_col in features.columns:
                        # Golden Cross / Death Cross
                        signals[f'ma_cross_{short_period}_{long_period}'] = np.where(\n                            features[short_ma_col] > features[long_ma_col], 1, -1\n                        )\n                        \n                        # Crossover momentum\n                        ma_ratio = features[short_ma_col] / features[long_ma_col]\n                        signals[f'ma_momentum_{short_period}_{long_period}'] = ma_ratio.diff()\n        \n        # Price vs Moving Average Signals\n        for period in [20, 50, 100]:\n            sma_col = f'sma_{period}'\n            if sma_col in features.columns:\n                # Price above/below MA\n                signals[f'price_above_sma_{period}'] = np.where(\n                    price_data['Close'] > features[sma_col], 1, -1\n                )\n                \n                # Distance from MA (normalized)\n                signals[f'price_ma_distance_{period}'] = (\n                    price_data['Close'] - features[sma_col]\n                ) / features[sma_col]\n        \n        # MACD Signals\n        if 'macd' in features.columns and 'macd_signal' in features.columns:\n            # MACD line above/below signal line\n            signals['macd_signal'] = np.where(\n                features['macd'] > features['macd_signal'], 1, -1\n            )\n            \n            # MACD histogram\n            if 'macd_histogram' in features.columns:\n                signals['macd_histogram_signal'] = np.where(\n                    features['macd_histogram'] > 0, 1, -1\n                )\n        \n        # Parabolic SAR Signals\n        if 'sar' in features.columns:\n            signals['sar_signal'] = np.where(\n                price_data['Close'] > features['sar'], 1, -1\n            )\n        \n        # Trend Strength Signals\n        for period in [20, 50]:\n            return_col = f'return_{period}'\n            if return_col in features.columns:\n                # Momentum signal\n                signals[f'momentum_signal_{period}'] = np.where(\n                    features[return_col] > 0, 1, -1\n                )\n                \n                # Strong momentum (top/bottom quartile)\n                momentum_quantiles = features[return_col].rolling(252).quantile([0.25, 0.75])\n                if not momentum_quantiles.empty:\n                    signals[f'strong_momentum_{period}'] = np.where(\n                        features[return_col] > momentum_quantiles.iloc[:, 1], 1,\n                        np.where(features[return_col] < momentum_quantiles.iloc[:, 0], -1, 0)\n                    )\n        \n        return signals\n    \n    def generate_mean_reversion_signals(self, features, price_data):\n        \"\"\"Generate mean reversion signals\"\"\"\n        signals = pd.DataFrame(index=features.index)\n        \n        # RSI Signals\n        for period in [14, 20, 50]:\n            rsi_col = f'rsi_{period}'\n            if rsi_col in features.columns:\n                # Overbought/Oversold\n                signals[f'rsi_overbought_{period}'] = np.where(\n                    features[rsi_col] > 70, -1,  # Sell signal\n                    np.where(features[rsi_col] < 30, 1, 0)  # Buy signal\n                )\n                \n                # RSI divergence (simplified)\n                rsi_ma = features[rsi_col].rolling(10).mean()\n                signals[f'rsi_divergence_{period}'] = np.where(\n                    features[rsi_col] > rsi_ma, 1, -1\n                )\n        \n        # Bollinger Bands Signals\n        for period in [20, 50]:\n            bb_pos_col = f'bb_position_{period}'\n            if bb_pos_col in features.columns:\n                # Band position signals\n                signals[f'bb_mean_reversion_{period}'] = np.where(\n                    features[bb_pos_col] > 0.8, -1,  # Near upper band - sell\n                    np.where(features[bb_pos_col] < 0.2, 1, 0)  # Near lower band - buy\n                )\n                \n                # Band squeeze (low volatility)\n                bb_width_col = f'bb_width_{period}'\n                if bb_width_col in features.columns:\n                    bb_width_ma = features[bb_width_col].rolling(50).mean()\n                    signals[f'bb_squeeze_{period}'] = np.where(\n                        features[bb_width_col] < bb_width_ma * 0.5, 1, 0\n                    )\n        \n        # Mean Reversion Signals\n        for period in [10, 20, 50]:\n            mr_col = f'mean_reversion_{period}'\n            if mr_col in features.columns:\n                # Strong deviation from mean\n                signals[f'mean_reversion_signal_{period}'] = np.where(\n                    features[mr_col] > 0.1, -1,  # Price too high\n                    np.where(features[mr_col] < -0.1, 1, 0)  # Price too low\n                )\n        \n        # Stochastic Signals\n        for period in [14, 20]:\n            stoch_k_col = f'stoch_k_{period}'\n            stoch_d_col = f'stoch_d_{period}'\n            \n            if stoch_k_col in features.columns and stoch_d_col in features.columns:\n                # Overbought/Oversold\n                signals[f'stoch_signal_{period}'] = np.where(\n                    features[stoch_k_col] > 80, -1,\n                    np.where(features[stoch_k_col] < 20, 1, 0)\n                )\n                \n                # %K crosses %D\n                signals[f'stoch_cross_{period}'] = np.where(\n                    features[stoch_k_col] > features[stoch_d_col], 1, -1\n                )\n        \n        # Williams %R Signals\n        for period in [14, 20]:\n            williams_col = f'williams_r_{period}'\n            if williams_col in features.columns:\n                signals[f'williams_signal_{period}'] = np.where(\n                    features[williams_col] > -20, -1,  # Overbought\n                    np.where(features[williams_col] < -80, 1, 0)  # Oversold\n                )\n        \n        return signals\n    \n    def generate_volatility_signals(self, features, price_data):\n        \"\"\"Generate volatility-based signals\"\"\"\n        signals = pd.DataFrame(index=features.index)\n        \n        # ATR-based signals\n        for period in [14, 20, 50]:\n            atr_col = f'atr_{period}'\n            if atr_col in features.columns:\n                # High volatility periods\n                atr_ma = features[atr_col].rolling(50).mean()\n                signals[f'high_volatility_{period}'] = np.where(\n                    features[atr_col] > atr_ma * 1.5, 1, 0\n                )\n                \n                # Low volatility periods (potential breakout)\n                signals[f'low_volatility_{period}'] = np.where(\n                    features[atr_col] < atr_ma * 0.5, 1, 0\n                )\n        \n        # Realized volatility signals\n        for period in [20, 50]:\n            vol_col = f'realized_vol_{period}'\n            if vol_col in features.columns:\n                # Volatility regime change\n                vol_ma = features[vol_col].rolling(100).mean()\n                signals[f'vol_regime_change_{period}'] = np.where(\n                    features[vol_col] > vol_ma * 1.2, 1,  # High vol regime\n                    np.where(features[vol_col] < vol_ma * 0.8, -1, 0)  # Low vol regime\n                )\n        \n        # Volatility breakout signals\n        for period in [10, 20]:\n            vol_col = f'volatility_{period}'\n            if vol_col in features.columns:\n                # Volatility expansion\n                vol_expanding = features[vol_col] > features[vol_col].shift(5)\n                price_breakout = abs(price_data['Close'].pct_change()) > features[vol_col]\n                \n                signals[f'vol_breakout_{period}'] = np.where(\n                    vol_expanding & price_breakout, 1, 0\n                )\n        \n        return signals\n    \n    def generate_volume_signals(self, features, price_data):\n        \"\"\"Generate volume-based signals\"\"\"\n        signals = pd.DataFrame(index=features.index)\n        \n        # Volume confirmation signals\n        for period in [10, 20]:\n            vol_ratio_col = f'volume_ratio_{period}'\n            if vol_ratio_col in features.columns:\n                # High volume confirmation\n                price_up = price_data['Close'] > price_data['Close'].shift(1)\n                high_volume = features[vol_ratio_col] > 1.5\n                \n                signals[f'volume_confirm_up_{period}'] = np.where(\n                    price_up & high_volume, 1, 0\n                )\n                \n                # Volume divergence\n                price_trend = price_data['Close'].rolling(5).mean().diff()\n                volume_trend = features[vol_ratio_col].rolling(5).mean().diff()\n                \n                signals[f'volume_divergence_{period}'] = np.where(\n                    (price_trend > 0) & (volume_trend < 0), -1,  # Price up, volume down\n                    np.where((price_trend < 0) & (volume_trend > 0), 1, 0)  # Price down, volume up\n                )\n        \n        # On-Balance Volume signals\n        if 'obv' in features.columns:\n            obv_ma = features['obv'].rolling(20).mean()\n            signals['obv_signal'] = np.where(\n                features['obv'] > obv_ma, 1, -1\n            )\n        \n        # Volume-Price Trend signals\n        if 'vpt' in features.columns:\n            vpt_ma = features['vpt'].rolling(20).mean()\n            signals['vpt_signal'] = np.where(\n                features['vpt'] > vpt_ma, 1, -1\n            )\n        \n        # Accumulation/Distribution signals\n        if 'ad_line' in features.columns:\n            ad_ma = features['ad_line'].rolling(20).mean()\n            signals['ad_signal'] = np.where(\n                features['ad_line'] > ad_ma, 1, -1\n            )\n        \n        return signals\n    \n    def generate_pattern_signals(self, features, price_data):\n        \"\"\"Generate pattern-based signals\"\"\"\n        signals = pd.DataFrame(index=features.index)\n        \n        # Gap signals\n        if 'overnight_gap' in features.columns:\n            # Gap up/down\n            signals['gap_signal'] = np.where(\n                features['overnight_gap'] > 0.02, 1,  # Gap up > 2%\n                np.where(features['overnight_gap'] < -0.02, -1, 0)  # Gap down > 2%\n            )\n            \n            # Gap reversal (mean reversion)\n            signals['gap_reversal'] = np.where(\n                features['overnight_gap'] > 0.05, -1,  # Large gap up - expect reversal\n                np.where(features['overnight_gap'] < -0.05, 1, 0)  # Large gap down - expect bounce\n            )\n        \n        # Doji patterns\n        if 'doji_ratio' in features.columns:\n            signals['doji_signal'] = np.where(\n                features['doji_ratio'] < 0.1, 1, 0  # Small body relative to range\n            )\n        \n        # Price efficiency signals\n        if 'price_efficiency' in features.columns:\n            # Low efficiency (choppy market)\n            signals['low_efficiency'] = np.where(\n                features['price_efficiency'] < 0.3, -1, 0\n            )\n            \n            # High efficiency (trending market)\n            signals['high_efficiency'] = np.where(\n                features['price_efficiency'] > 0.8, 1, 0\n            )\n        \n        return signals\n    \n    def generate_ensemble_signals(self, all_signals, method='voting', weights=None):\n        \"\"\"Combine multiple signals using ensemble methods\"\"\"\n        if all_signals.empty:\n            return pd.DataFrame()\n        \n        ensemble_signals = pd.DataFrame(index=all_signals.index)\n        \n        if method == 'voting':\n            # Simple majority voting\n            ensemble_signals['ensemble_vote'] = all_signals.apply(\n                lambda row: 1 if row.sum() > 0 else (-1 if row.sum() < 0 else 0), axis=1\n            )\n            \n            # Weighted voting\n            if weights is not None and len(weights) == len(all_signals.columns):\n                weighted_sum = (all_signals * weights).sum(axis=1)\n                ensemble_signals['ensemble_weighted'] = np.where(\n                    weighted_sum > 0, 1, np.where(weighted_sum < 0, -1, 0)\n                )\n        \n        elif method == 'strength':\n            # Signal strength based on agreement\n            signal_strength = all_signals.abs().sum(axis=1) / len(all_signals.columns)\n            signal_direction = np.sign(all_signals.sum(axis=1))\n            \n            ensemble_signals['ensemble_strength'] = signal_strength * signal_direction\n            \n            # Strong signals only\n            ensemble_signals['ensemble_strong'] = np.where(\n                signal_strength > 0.6, signal_direction, 0\n            )\n        \n        elif method == 'consensus':\n            # Require consensus (e.g., 70% agreement)\n            total_signals = len(all_signals.columns)\n            consensus_threshold = 0.7\n            \n            positive_signals = (all_signals > 0).sum(axis=1)\n            negative_signals = (all_signals < 0).sum(axis=1)\n            \n            ensemble_signals['ensemble_consensus'] = np.where(\n                positive_signals >= total_signals * consensus_threshold, 1,\n                np.where(negative_signals >= total_signals * consensus_threshold, -1, 0)\n            )\n        \n        return ensemble_signals\n    \n    def generate_ml_signals(self, features, returns, lookback_window=252, min_samples=100):\n        \"\"\"Generate signals using machine learning models\"\"\"\n        if len(features) < min_samples:\n            return pd.DataFrame(index=features.index)\n        \n        signals = pd.DataFrame(index=features.index)\n        \n        # Prepare target variable (binary: up/down)\n        target = (returns > 0).astype(int)\n        \n        # Remove features with too many NaN values\n        feature_cols = features.select_dtypes(include=[np.number]).columns\n        valid_features = features[feature_cols].dropna(axis=1, thresh=len(features) * 0.8)\n        \n        if valid_features.empty:\n            return signals\n        \n        # Walk-forward analysis\n        ml_predictions = []\n        \n        for i in range(lookback_window, len(features)):\n            try:\n                # Training data\n                train_start = max(0, i - lookback_window)\n                train_end = i\n                \n                X_train = valid_features.iloc[train_start:train_end].fillna(method='ffill').fillna(0)\n                y_train = target.iloc[train_start:train_end]\n                \n                # Remove samples with NaN targets\n                valid_idx = ~y_train.isna()\n                X_train = X_train[valid_idx]\n                y_train = y_train[valid_idx]\n                \n                if len(X_train) < min_samples or y_train.nunique() < 2:\n                    ml_predictions.append(0)\n                    continue\n                \n                # Scale features\n                scaler = StandardScaler()\n                X_train_scaled = scaler.fit_transform(X_train)\n                \n                # Train models\n                models = {\n                    'rf': RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42),\n                    'gb': GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42),\n                    'lr': LogisticRegression(random_state=42, max_iter=100)\n                }\n                \n                predictions = {}\n                for name, model in models.items():\n                    try:\n                        model.fit(X_train_scaled, y_train)\n                        \n                        # Predict next period\n                        X_test = valid_features.iloc[i:i+1].fillna(method='ffill').fillna(0)\n                        X_test_scaled = scaler.transform(X_test)\n                        \n                        pred_proba = model.predict_proba(X_test_scaled)[0]\n                        predictions[name] = pred_proba[1] - pred_proba[0]  # Confidence score\n                        \n                    except Exception as e:\n                        predictions[name] = 0\n                \n                # Ensemble prediction\n                ensemble_pred = np.mean(list(predictions.values()))\n                ml_predictions.append(ensemble_pred)\n                \n            except Exception as e:\n                ml_predictions.append(0)\n        \n        # Add predictions to signals\n        if ml_predictions:\n            ml_series = pd.Series([0] * lookback_window + ml_predictions, index=features.index)\n            \n            # Convert to discrete signals\n            signals['ml_signal'] = np.where(\n                ml_series > 0.1, 1,\n                np.where(ml_series < -0.1, -1, 0)\n            )\n            \n            # Signal strength\n            signals['ml_strength'] = ml_series\n        \n        return signals\n    \n    def generate_all_signals(self, features, price_data, returns=None, include_ml=False):\n        \"\"\"Generate all types of signals\"\"\"\n        all_signals = pd.DataFrame(index=features.index)\n        \n        print(\"Generating signals...\")\n        \n        # Trend signals\n        trend_signals = self.generate_trend_signals(features, price_data)\n        all_signals = pd.concat([all_signals, trend_signals], axis=1)\n        print(f\"  ✓ Trend signals: {len(trend_signals.columns)}\")\n        \n        # Mean reversion signals\n        mr_signals = self.generate_mean_reversion_signals(features, price_data)\n        all_signals = pd.concat([all_signals, mr_signals], axis=1)\n        print(f\"  ✓ Mean reversion signals: {len(mr_signals.columns)}\")\n        \n        # Volatility signals\n        vol_signals = self.generate_volatility_signals(features, price_data)\n        all_signals = pd.concat([all_signals, vol_signals], axis=1)\n        print(f\"  ✓ Volatility signals: {len(vol_signals.columns)}\")\n        \n        # Volume signals\n        volume_signals = self.generate_volume_signals(features, price_data)\n        all_signals = pd.concat([all_signals, volume_signals], axis=1)\n        print(f\"  ✓ Volume signals: {len(volume_signals.columns)}\")\n        \n        # Pattern signals\n        pattern_signals = self.generate_pattern_signals(features, price_data)\n        all_signals = pd.concat([all_signals, pattern_signals], axis=1)\n        print(f\"  ✓ Pattern signals: {len(pattern_signals.columns)}\")\n        \n        # Machine learning signals (optional)\n        if include_ml and returns is not None:\n            ml_signals = self.generate_ml_signals(features, returns)\n            all_signals = pd.concat([all_signals, ml_signals], axis=1)\n            print(f\"  ✓ ML signals: {len(ml_signals.columns)}\")\n        \n        # Ensemble signals\n        signal_cols = [col for col in all_signals.columns if col not in ['ml_strength']]\n        if signal_cols:\n            ensemble_signals = self.generate_ensemble_signals(\n                all_signals[signal_cols], method='voting'\n            )\n            all_signals = pd.concat([all_signals, ensemble_signals], axis=1)\n            print(f\"  ✓ Ensemble signals: {len(ensemble_signals.columns)}\")\n        \n        print(f\"Total signals generated: {len(all_signals.columns)}\")\n        \n        return all_signals\n    \n    def evaluate_signal_performance(self, signals, returns, holding_periods=[1, 5, 10]):\n        \"\"\"Evaluate signal performance\"\"\"\n        performance_results = {}\n        \n        for signal_name in signals.columns:\n            signal_series = signals[signal_name]\n            \n            # Skip non-numeric signals\n            if not pd.api.types.is_numeric_dtype(signal_series):\n                continue\n            \n            signal_performance = {}\n            \n            for period in holding_periods:\n                # Calculate forward returns for signal positions\n                forward_returns = returns.shift(-period)\n                \n                # Long positions (signal = 1)\n                long_mask = signal_series == 1\n                long_returns = forward_returns[long_mask]\n                \n                # Short positions (signal = -1)\n                short_mask = signal_series == -1\n                short_returns = -forward_returns[short_mask]  # Invert for short positions\n                \n                # Combined returns\n                all_signal_returns = pd.concat([long_returns, short_returns])\n                \n                if len(all_signal_returns) > 0:\n                    signal_performance[f'period_{period}'] = {\n                        'mean_return': all_signal_returns.mean(),\n                        'std_return': all_signal_returns.std(),\n                        'sharpe_ratio': all_signal_returns.mean() / all_signal_returns.std() if all_signal_returns.std() > 0 else 0,\n                        'hit_rate': (all_signal_returns > 0).mean(),\n                        'num_trades': len(all_signal_returns),\n                        'total_return': all_signal_returns.sum()\n                    }\n                else:\n                    signal_performance[f'period_{period}'] = {\n                        'mean_return': 0, 'std_return': 0, 'sharpe_ratio': 0,\n                        'hit_rate': 0, 'num_trades': 0, 'total_return': 0\n                    }\n            \n            performance_results[signal_name] = signal_performance\n        \n        return performance_results\n    \n    def get_signal_summary(self, signals):\n        \"\"\"Get summary statistics of generated signals\"\"\"\n        summary = {\n            'total_signals': len(signals.columns),\n            'signal_types': {},\n            'signal_activity': {},\n            'signal_correlations': None\n        }\n        \n        # Categorize signals\n        categories = {\n            'trend': ['ma_', 'macd', 'sar', 'momentum'],\n            'mean_reversion': ['rsi_', 'bb_', 'stoch_', 'williams'],\n            'volatility': ['vol_', 'atr_'],\n            'volume': ['volume_', 'obv', 'vpt', 'ad_'],\n            'pattern': ['gap_', 'doji', 'efficiency'],\n            'ensemble': ['ensemble_'],\n            'ml': ['ml_']\n        }\n        \n        for category, prefixes in categories.items():\n            count = sum(1 for col in signals.columns \n                       if any(prefix in col for prefix in prefixes))\n            if count > 0:\n                summary['signal_types'][category] = count\n        \n        # Signal activity (how often each signal is non-zero)\n        for col in signals.columns:\n            if pd.api.types.is_numeric_dtype(signals[col]):\n                activity = (signals[col] != 0).mean()\n                summary['signal_activity'][col] = activity\n        \n        # Signal correlations (sample)\n        numeric_signals = signals.select_dtypes(include=[np.number])\n        if len(numeric_signals.columns) > 1:\n            corr_matrix = numeric_signals.corr()\n            \n            # Find highly correlated signals\n            high_corr_pairs = []\n            for i in range(len(corr_matrix.columns)):\n                for j in range(i+1, len(corr_matrix.columns)):\n                    corr_val = corr_matrix.iloc[i, j]\n                    if abs(corr_val) > 0.7:  # High correlation threshold\n                        high_corr_pairs.append((\n                            corr_matrix.columns[i], \n                            corr_matrix.columns[j], \n                            corr_val\n                        ))\n            \n            summary['high_correlations'] = high_corr_pairs[:10]  # Top 10\n        \n        return summary
